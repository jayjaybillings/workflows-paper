\chapter{A review of workflows and taxonomies}

\section{Workflows}\label{workflows}

As mentioned previously, one of the most challenging aspects of studying
workflows is the way the vocabulary has been overloaded unintentionally.
It is somewhat clearer to understand them by considering the historial
perspective.

The use and study of workflows and the initial implementation of
workflow management systems developed in the business world with the
need to automate business processes. Lud\"{a}scher et al. ascribe the
origins of workflows and workflow management systems to ``office
automation'' trends in the 1970s, \cite{ludascher_scientific_2006}. Van Der
Aalst argues that ``workflows'' arose from the needs of businesses to not only
execute tasks, but ``to manage the flow of work through the
organization,'' and that managing workflows is the natural evolution
from the monolithic applications of the 1960s to applications that rely
on external functionality in the 1990s, \cite{van_der_aalst_application_1998}.
(One might argue that Van Der Aalst's depiction continues today with the
growth of the ``microservices'' architectural movement.) By 1995, in the
presence of many workflow tools, the Workflow Management Coalition had developed a ``standard'' definition of
workflows, \cite{hollingsworth_workflow_1993},

\begin{displayquote}
A Workflow is the automation of a business process, in whole or part, during
which documents, information or tasks are passed from one participant (a 
resource; human or machine) to another for action, according a set of 
procedural rules. 
\end{displayquote}

In the early 2000s, workflow systems started finding use in scientific
contexts where process automation was required for scientific uses
instead of traditional business uses. The focus of scientific workflows,
at the time, also shifted to focus primarily on data processing for
large ``grids'' of networked services, \cite{yu_taxonomy_2005}. Yu and Buyya
define a workflow as

\begin{displayquote}
... a collection of tasks that are processed on distributed resources in a
well-defined order to accomplish a specific goal.
\end{displayquote}

This definition is important because of what is missing: the human
element. For many in the scientific workflows community this has become
the standard definition of a workflow and the involvement of humans
results not in a single workflow, but two workflows spanned by a human.
Machines or instruments are absent from the definition as well, but in
practice many modern scientific workflows are launched automatically
when data ``comes off'' of instruments because they remain the primary
source of data in grid workflows, (c.f. - \cite{megino_panda:_2015}).

In addition to ``grid workflows,'' the scientific community started
exploring ``modeling and simulation'' workflows which focus not on data
flow, but on the orchestration of activities related to modeling and
simulation instead, sometimes on small local computers, but often on the
largest of the world's ``Leadership Class'' supercomputers. These
workflows typically fall into a subset of their more general cousins
that can be found in the grid or business communities, but unlike grid
workflows they tend to require human interaction in one way or another.
Some of these workflows are defined in the context of a particular way
of working, such as the Automation, Data, Environment, and Sharing
(ADES) model of Pizzi et al., \cite{pizzi_aiida:_2016}, the
``Design-to-Analysis'' model of Clay et al., \cite{clay_incorporating_2015}, or
the model of Billings et al. presented later in this work during the
discussion on the Eclipse Integrated Computational Environment. However,
many scientific workflows, while exceptionally well defined, remain hard
coded into dedicated environments developed for the sole purpose of
executing that single or at most a few related workflows.

Additional types of workflows in the scientific community include
workflows that process ensembles of calculations, \cite{montoya_apex_2016},
and workflows that are used for testing software.

\section{Taxonomies and
Classification}\label{taxonomies-and-classification}

There have been several efforts to classify, survey or develop taxonomies
for workflows. Yu and Buyya are the only source that provides what can
be truly considered a ``taxonomy,'' by showing the hierarchical
relationships between workflow concepts. Most of the other efforts
discussed below, while claiming to produce taxonomies, in fact produce
controlled vocabularies.

Human involvement is critical in some workflows which require adaptive
management, as shown by Han and Bussler, \cite{han_taxonomy_1998}. Their work
considers adaptive workflow management in the context of healthcare
workflows and argues that workflow technology in 2002 was incapable of
adapting sufficiently to meet the unexpected needs of medical personnel.
Along with unexpected needs (``changing environment''), they cite the
evolution of software systems (``technical advances'') as another
critical area that leads to required changes in workflow management
systems.

Han and Bussler discuss situations that lead to ``ad-hoc derivation'' of
workflows. ``Ad-hoc derivation'' in this case means generating extra
workflow steps or details, such as converting from an abstract to a
concrete workflow as Pegasus and other grid workflow systems do.
Specifically, Han and Bussler cite dynamic refinement, user involvement,
unpredictable events and erroneous situations as systems that require
the workflow to behave in an unplanned way, and for which
workflow managements systems should be prepared. Meta-models, open-point
(more commonly known as ``extension point'') or hybrid approaches are
proposed as solutions.

It is important to note that Han and Bussler consider only business
workflows and management systems, not scientific workflows and
management systems. In this context they also share some important
wisdom that is, arguably, of equal importance to scientific workflows:

\begin{displayquote}
Workflow systems do not exist for their own purposes. They
are a constituent component of a business system. A business system is usually domain
specific.
\end{displayquote}

This is an important consideration for scientific workflows because the
``business logic'' of scientific workflows is ``domain logic'' that is
highly specific to the scientific domain under consideration. This
necessarily leads to a diverse ecosystem of workflow systems.

Yu and Buyya developed a taxonomy for workflow management systems on
grids that sought to capture the architectural style while identifying
comparison criteria, \cite{yu_taxonomy_2005}. Their work is notable because it
largely avoids a discussion of applications and focuses purely on the
functional properties of the workflow management systems as they exist
on the grids. Yu and Buyya root their taxonomy on five core elements of
grid-based workflow management systems: workflow design, information
retrieval, workflow scheduling, fault tolerance, and data movement.
While many of the properties and taxonomic elements they describe seem
common to all systems, others would appear to be grid-specific at present, such
as ``Workflow QoS Constraints''. Their work also shows how thirteen common grid
workflow management systems, including Pegasus and Kepler, are covered by the
taxonomy. Like other authors, Yu and Buyya cite the lack of standardized
workflow syntax and language as sources of interoperability issues. Yu's and
Buyya's work is extremely detailed and a very helpful resource for
understanding grid workflows.

Scientific workflow management systems have flourished since their
inception, although not without significant overlap and duplication of
effort. The survey of scientific workflow management systems by Barker
and Hemert illustrates both the growth and problems while also providing
important observations and recommendations on the topic,
\cite{barker_scientific_2007}.

Barker and Hemert also provide key insights into the history of
workflow management systems as an important part of business
automation. The authors make an important comparison between traditional
business workflow management systems and their scientific counterparts,
citing in particular that traditional business workflow tools employ the
wrong abstraction for scientists They define workflows using the
``standard'' definition from the Workflow Management Coalition,
previously mentioned above.

The discussion points that Barker and Hemert raise are important because
of their continuing importance and relevance today, particularly the
need to enable programmability through standard languages instead of
custom, proprietary languages. (The reader is encouraged to read the
 entire paper for more details.) Sticking to
standards is also important and perhaps illustrated best by Barker's and
Hemert's statement that

\begin{displayquote}
If software development and tool support terminates on one proprietary 
framework, workflows will need to be re-implemented from scratch.
\end{displayquote}

This is an important point even for workflow tools that do not use
proprietary standards, but ``roll their own'' solutions. What can be
done to support those tools and reproduce those workflows once support
for continued development ends?

Notably, in their discussion about the Kepler workflow management
system, Barker and Hemert state that

\begin{displayquote}
Actors are re-usable independent blocks of computation, such as:
Web Services, database calls, etc.
\end{displayquote}

Jha and Turilli have proposed using independent ``building blocks'' as
an approach to scientific workflows which espouses a similar
relationship to infrastructure services, \cite{jha_building_2016}. The
similarity is notable and the exact relationship between Jha's blocks and
Actor-Oriented Programming merit further investigation. 
Jha and Turilli provide an ambiguous definition of workflows, stating
that workflows are both comprised of tasks and provide a description of
the resources and constraints for each task. The ambiguity rises from
the definition of ``tasks.'' If tasks are compute processes, then their
definition is equivalent to that of grid workflows. However, if a task
could include human interaction during execution, then they have a much
broader definition than what is normally found in the grid literature,
and their definition more closely resembles a business workflow.
Building blocks, on the other hand, are concretely defined as those
pieces of middleware that are self-sufficient, interoperable,
composable, and extensible, (with detailed definitions of each
provided). The RADICAL-Cybertools suite of software modules from Jha's
group is presented as a sample set of building blocks and two case
studies where these tools were successfully as such are presented.

Montoya et al. discuss workflows needs for the Alliance for Application
Performance at Extreme Scale (APEX), \cite{nersc_apex_2016}, and describe
three main classes of workflows: Simulation Science, Uncertainty
Quantification (UQ), and High Throughput Computing (HTC),
\cite{montoya_apex_2016}.
HTC workflows start with the collection of data from experiments that is in turn transported to large compute facilities for
processing. Many grid workflows are HTC workflows, but not all HTC
workflows are grid workflows since some HTC workflows, such as those
those presented by Montoya et al., maybe be run on large resources that
are not traditionally ``grid machines.'' Simulation science workflows,
referred to above as modeling and simulation workflows, are those
workflows that are primarily focused on modeling and simulation
activities. UQ workflows build on modeling and simulation workflows by
executing ensembles of jobs or ensembles of whole workflows to quantify
uncertainty in simulation results. Montoya et al. also provide a detailed
mapping of each workflow type to optimal hardware resources for the APEX
program.

The U.S. Department of Energy sponsored the \emph{DOE NGNS/CS Scientific
Workflows Workshop} on April 20-21st 2015. In the report, Deelman et al.
describe the requirements and research directions for scientific
workflows for the exascale environment, \cite{deelman_future_2015}. The report
describes scientific workflows primarily by three application types:
Simulations, Instruments, and Collaborations. The findings of the workshop are
comprehensive and encouraging, with recommendations for research
priorities in Application Requirements, Hardware Systems, System
Software, WMS Design and Execution, Programming and Usability,
Provenance Capture, Validation, and Workflow Science.

The definitions of a ``workflow'' and ``workflow management systems''
are thoroughly explored and put into context for the purposes of the
workshop. The authors of the report are very careful to define workflows
not just as a collection of managed processes, which is common, but in
such a way that it is clear that reproducibility, mobility and some
degree of generality are required by both the description of the
workflow and the management system. \footnote{The report appears to provide
three separate definitions for ``workflow'' on pages 6, 9 and 10.}

The brief summary of different workflow models above is a sample of the
confusion in the ``marketplace'' and illustrates the lack of a coherent
understanding of workflows.

The next section presents the workflow model, system architecture and
applications of the Eclipse Integrated Computational Environment. This
model limits its scope to high-performance computing (HPC) and to the
set of possible workflows that come creating input, executing jobs,
analyzing results, managing data, and modifying code. However, as ``limited'' as
ICE's model may be, it shows significant ability to interoperate with
other workflow engines. This and other qualities of the system are why
it is revisited later as a proposed platform for testing an
interoperability layer.

